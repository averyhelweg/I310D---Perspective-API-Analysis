# I310D---Perspective-API-Analysis

### In this project I analyzed the Perspective API for Bias and patters relating to a comments toxicity score and weather or not the comment was rated toxic by the rater. I was able to start my project by running some brief words and phrases through the API to establish a basis of understanding of how the API worked and to see if there were any patterns in toxicity scores. In my initial analysis I was able to conclude a few different things such as, the tendency of the API to rate uppercase comments with a higher toxicisity score even if it was the same word or phrase, that phrases and words more specifically profanities in the present tense (verbs) tended to be ranked with higher toxicisity. I then decided I was going to test the uppercase hypothesis and conducted a small test where I ran about 14 phrases through the API to see if a comment was liklier to recieve higher toxicity scores if it was in uppercase and based on my results I was able to conclude that the hypothesis is true, words and phrases in all uppercase letters will tend to receive a higher toxicity score than those that aren't even if its the exact same word/phrase. However I will note that this trend appears more on comments that are already negative, for example comments that already have profanities. After I ran the test on my hypothesis I used both rounds of testing that I conducted to establish my toxicity score threshold. I determined my threshold to be 0.68 because in my brief analysis I noticed that most words/phrases that I would consider to be more of a toxic nature scored at 0.68 and above. After selecting a threshold I created a new dataset (included in the repository) and opened it up to explore why there are comments above my established threshold that arent rated toxic by the rater. To do this I used false positives from the top 5 and bottom 5 values in the dataset. 

##### I was slightly surprised by the finding about the uppercase words and phrases being more likely to recieve higher toxicity ratings because if its the same phrase just lowercase it still maintains the same overall meaning. I do feel that there are certainly biases in the API such as entries that refrence religion, ethniticy, or controversial topics being rated higher even if there wasn't a negative connotation to the comment. I also think that it's more difficult for the API to process longer entries so those are common spots where there may be either more false negatives or positives in relation to toxicity score and weather or not the comment was rated toxic by the rater. 

What theories do you have about why your results are what they are?

should include all of your documentation about your analysis (what you are testing, your hypotheses, and your results). The LICENSE should be an MIT License
